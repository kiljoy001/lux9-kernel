/*
 * Unified borrow checker for kernel primitives
 * Provides Rust-style ownership and borrowing for locks, memory, I/O, etc.
 */

#include "u.h"
#include "portlib.h"
#include "mem.h"
#include "dat.h"
#include "fns.h"
#include "borrowchecker.h"

/* Global borrow pool */
struct BorrowPool borrowpool;

/* Static early-boot hash table (before xinit) */
#define EARLY_BOOT_BUCKETS 256
#define EARLY_BOOT_OWNERS 512  /* Pool of pre-allocated BorrowOwner structs */
#define EARLY_BOOT_SHARED 128  /* Pool of pre-allocated SharedBorrower structs */
static struct BorrowBucket early_boot_buckets[EARLY_BOOT_BUCKETS];
static struct BorrowOwner early_boot_owner_pool[EARLY_BOOT_OWNERS];
static struct SharedBorrower early_boot_shared_pool[EARLY_BOOT_SHARED];
static int early_boot_owner_next = 0;
static int early_boot_shared_next = 0;
static int using_early_boot = 0;

/* Initialize the borrow pool */
void
borrowinit(void)
{
	ulong i;
	extern int xinit_done;  /* Defined in xalloc.c, set after xinit() completes */

	/* Check if we're in early boot (before xinit) */
	if (!xinit_done) {
		/* Use static pre-allocated hash table for early boot */
		borrowpool.nbuckets = EARLY_BOOT_BUCKETS;
		borrowpool.owners = early_boot_buckets;
		using_early_boot = 1;
		print("borrowinit: using early-boot static hash table (%d buckets)\n", EARLY_BOOT_BUCKETS);
	} else {
		/* Normal initialization with xalloc */
		borrowpool.nbuckets = 1024; /* Arbitrary size, can be tuned */
		borrowpool.owners = xalloc(borrowpool.nbuckets * sizeof(struct BorrowBucket));
		if (borrowpool.owners == nil) {
			panic("borrowinit: failed to allocate hash table");
		}
		using_early_boot = 0;
		print("borrowinit: using xalloc hash table (%d buckets)\n", (int)borrowpool.nbuckets);
	}

	for (i = 0; i < borrowpool.nbuckets; i++) {
		borrowpool.owners[i].head = nil;
	}

	borrowpool.nowners = 0;
	borrowpool.nshared = 0;
	borrowpool.nmut = 0;
}

/* Hash function for uintptr keys */
ulong
borrow_hash(uintptr key)
{
	if(borrowpool.nbuckets == 0 || borrowpool.owners == nil)
		panic("borrow_hash: borrowinit not called");
	/* Simple hash: use the lower bits */
	return key % borrowpool.nbuckets;
}

/* Find BorrowOwner for a key */
static struct BorrowOwner*
find_owner(uintptr key)
{
	ulong hash = borrow_hash(key);
	struct BorrowOwner *owner = borrowpool.owners[hash].head;

	while (owner != nil) {
		if (owner->key == key) {
			return owner;
		}
		owner = owner->next;
	}
	return nil;
}

/* Create new BorrowOwner for a key */
static struct BorrowOwner*
create_owner(uintptr key)
{
	ulong hash = borrow_hash(key);
	struct BorrowOwner *owner;

	/* Use static pool during early boot, xalloc otherwise */
	if (using_early_boot) {
		if (early_boot_owner_next >= EARLY_BOOT_OWNERS) {
			print("create_owner: early boot pool exhausted (%d/%d)\n",
			      early_boot_owner_next, EARLY_BOOT_OWNERS);
			return nil;
		}
		owner = &early_boot_owner_pool[early_boot_owner_next++];
	} else {
		owner = xalloc(sizeof(struct BorrowOwner));
		if (owner == nil) {
			return nil;
		}
	}

	owner->key = key;
	owner->owner = nil;
	owner->state = BORROW_FREE;
	owner->system_owner = OWNER_BOOTLOADER;  /* Default to bootloader ownership */
	owner->is_system_owned = 0;  /* Not system owned by default */
	owner->shared_count = 0;
	owner->shared_list = nil;  /* Initialize shared borrower list */
	owner->mut_borrower = nil;
	owner->acquired_ns = 0;
	owner->borrow_deadline_ns = 0;
	owner->borrow_count = 0;
	owner->next = borrowpool.owners[hash].head;
	borrowpool.owners[hash].head = owner;

	borrowpool.nowners++;
	return owner;
}

/* Acquire ownership of a resource */
enum BorrowError
borrow_acquire(Proc *p, uintptr key)
{
	struct BorrowOwner *owner;

	if (p == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil) {
		owner = create_owner(key);
		if (owner == nil) {
			iunlock(&borrowpool.lock);
			return BORROW_ENOMEM;
		}
	}

	if (owner->state != BORROW_FREE) {
		iunlock(&borrowpool.lock);
		return BORROW_EALREADY;
	}

	owner->owner = p;
	owner->state = BORROW_EXCLUSIVE;
	owner->acquired_ns = todget(nil, nil);
	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Release ownership of a resource */
enum BorrowError
borrow_release(Proc *p, uintptr key)
{
	struct BorrowOwner *owner, *prev;
	ulong hash;

	if (p == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (owner->owner != p) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (owner->shared_count > 0 || owner->shared_list != nil || owner->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EBORROWED;
	}

	owner->owner = nil;
	owner->state = BORROW_FREE;
	borrowpool.nowners--;

	/* FIX MEMORY LEAK: Remove and free the owner entry from hash table */
	hash = borrow_hash(key);
	prev = nil;
	for (owner = borrowpool.owners[hash].head; owner != nil; owner = owner->next) {
		if (owner->key == key) {
			if (prev == nil) {
				borrowpool.owners[hash].head = owner->next;
			} else {
				prev->next = owner->next;
			}
			if (!using_early_boot) {
				xfree(owner);
			}
			break;
		}
		prev = owner;
	}

	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Transfer ownership from one process to another */
enum BorrowError
borrow_transfer(Proc *from, Proc *to, uintptr key)
{
	struct BorrowOwner *owner;

	if (from == nil || to == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (owner->owner != from) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (owner->shared_count > 0 || owner->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EBORROWED;
	}

	owner->owner = to;
	owner->acquired_ns = todget(nil, nil);
	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Borrow resource as shared */
enum BorrowError
borrow_borrow_shared(Proc *owner, Proc *borrower, uintptr key)
{
	struct BorrowOwner *own;
	struct SharedBorrower *sb;

	if (owner == nil || borrower == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (own->owner != owner) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (own->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EMUTBORROW;
	}

	/* Check if this borrower already has a shared borrow */
	for (sb = own->shared_list; sb != nil; sb = sb->next) {
		if (sb->proc == borrower) {
			iunlock(&borrowpool.lock);
			return BORROW_EALREADY;  /* Already has a shared borrow */
		}
	}

	/* Allocate new shared borrower node */
	if (using_early_boot) {
		if (early_boot_shared_next >= EARLY_BOOT_SHARED) {
			iunlock(&borrowpool.lock);
			return BORROW_ENOMEM;
		}
		sb = &early_boot_shared_pool[early_boot_shared_next++];
	} else {
		sb = xalloc(sizeof(struct SharedBorrower));
		if (sb == nil) {
			iunlock(&borrowpool.lock);
			return BORROW_ENOMEM;
		}
	}

	/* Add to front of shared list */
	sb->proc = borrower;
	sb->next = own->shared_list;
	own->shared_list = sb;

	own->shared_count++;
	own->borrow_count++;
	if (own->state == BORROW_EXCLUSIVE) {
		own->state = BORROW_SHARED_OWNED;
	}
	if (own->shared_count == 1) {
		borrowpool.nshared++;
	}

	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Borrow resource as mutable */
enum BorrowError
borrow_borrow_mut(Proc *owner, Proc *borrower, uintptr key)
{
	struct BorrowOwner *own;

	if (owner == nil || borrower == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (own->owner != owner) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (own->shared_count > 0) {
		iunlock(&borrowpool.lock);
		return BORROW_ESHAREDBORROW;
	}

	if (own->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EMUTBORROW;
	}

	own->mut_borrower = borrower;
	own->state = BORROW_MUT_LENT;
	own->borrow_count++;
	borrowpool.nmut++;

	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Return a shared borrow */
enum BorrowError
borrow_return_shared(Proc *borrower, uintptr key)
{
	struct BorrowOwner *own;
	struct SharedBorrower *sb, *prev;

	if (borrower == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (own->shared_count == 0 || own->shared_list == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTBORROWED;
	}

	/* Find and remove borrower from shared list */
	prev = nil;
	for (sb = own->shared_list; sb != nil; sb = sb->next) {
		if (sb->proc == borrower) {
			/* Found it - remove from list */
			if (prev == nil) {
				own->shared_list = sb->next;
			} else {
				prev->next = sb->next;
			}
			/* Only free if not from early boot pool */
			if (!using_early_boot) {
				xfree(sb);
			}

			own->shared_count--;
			if (own->shared_count == 0) {
				own->state = BORROW_EXCLUSIVE;
				borrowpool.nshared--;
			}

			iunlock(&borrowpool.lock);
			return BORROW_OK;
		}
		prev = sb;
	}

	/* Borrower not found in list */
	iunlock(&borrowpool.lock);
	return BORROW_ENOTBORROWED;
}

/* Return a mutable borrow */
enum BorrowError
borrow_return_mut(Proc *borrower, uintptr key)
{
	struct BorrowOwner *own;

	if (borrower == nil) {
		return BORROW_EINVAL;
	}

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (own->mut_borrower != borrower) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTBORROWED;
	}

	own->mut_borrower = nil;
	own->state = BORROW_EXCLUSIVE;
	borrowpool.nmut--;

	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Query functions */
int
borrow_is_owned(uintptr key)
{
	struct BorrowOwner *owner;
	int owned;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	owned = (owner != nil && owner->state != BORROW_FREE);
	iunlock(&borrowpool.lock);

	return owned;
}

Proc*
borrow_get_owner(uintptr key)
{
	struct BorrowOwner *owner;
	Proc *p;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	p = (owner != nil) ? owner->owner : nil;
	iunlock(&borrowpool.lock);

	return p;
}

int
borrow_get_owner_snapshot(uintptr key, struct BorrowOwner *out)
{
	struct BorrowOwner *owner;
	int ok = 0;

	if(out == nil)
		return 0;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if(owner != nil){
		*out = *owner;
		out->next = nil;
		ok = 1;
	}
	iunlock(&borrowpool.lock);

	return ok;
}

enum BorrowState
borrow_get_state(uintptr key)
{
	struct BorrowOwner *owner;
	enum BorrowState state;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	state = (owner != nil) ? owner->state : BORROW_FREE;
	iunlock(&borrowpool.lock);

	return state;
}

int
borrow_can_borrow_shared(uintptr key)
{
	struct BorrowOwner *owner;
	int can;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	can = (owner != nil && owner->state != BORROW_FREE && owner->mut_borrower == nil);
	iunlock(&borrowpool.lock);

	return can;
}

int
borrow_can_borrow_mut(uintptr key)
{
	struct BorrowOwner *owner;
	int can;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	can = (owner != nil && owner->state != BORROW_FREE &&
	       owner->shared_count == 0 && owner->mut_borrower == nil);
	iunlock(&borrowpool.lock);

	return can;
}

/* Cleanup all resources for a process */
void
borrow_cleanup_process(Proc *p)
{
	ulong i;
	struct BorrowOwner *owner, *prev, *next;
	struct SharedBorrower *sb, *sb_next;
	int cleaned = 0;

	if (p == nil) {
		return;
	}

	ilock(&borrowpool.lock);

	for (i = 0; i < borrowpool.nbuckets; i++) {
		prev = nil;
		owner = borrowpool.owners[i].head;
		while (owner != nil) {
			next = owner->next;

			if (owner->owner == p) {
				/* Force release - free all shared borrowers */
				for (sb = owner->shared_list; sb != nil; sb = sb_next) {
					sb_next = sb->next;
					if (!using_early_boot) {
						xfree(sb);
					}
				}
				owner->shared_list = nil;
				owner->owner = nil;
				owner->state = BORROW_FREE;
				owner->shared_count = 0;
				owner->mut_borrower = nil;
				borrowpool.nowners--;
				cleaned++;
			}

			if (owner->mut_borrower == p) {
				owner->mut_borrower = nil;
				if (owner->state == BORROW_MUT_LENT) {
					owner->state = BORROW_EXCLUSIVE;
				}
				borrowpool.nmut--;
				cleaned++;
			}

			/* Remove this process from shared borrower list if present */
			struct SharedBorrower *sb_prev = nil;
			for (sb = owner->shared_list; sb != nil; sb = sb_next) {
				sb_next = sb->next;
				if (sb->proc == p) {
					/* Remove from list */
					if (sb_prev == nil) {
						owner->shared_list = sb_next;
					} else {
						sb_prev->next = sb_next;
					}
					if (!using_early_boot) {
						xfree(sb);
					}
					owner->shared_count--;
					if (owner->shared_count == 0 && owner->state == BORROW_SHARED_OWNED) {
						owner->state = BORROW_EXCLUSIVE;
						borrowpool.nshared--;
					}
					cleaned++;
				} else {
					sb_prev = sb;
				}
			}

			/* Remove from list if freed and no borrows */
			if (owner->state == BORROW_FREE && owner->shared_count == 0 &&
			    owner->shared_list == nil && owner->mut_borrower == nil) {
				if (prev == nil) {
					borrowpool.owners[i].head = next;
				} else {
					prev->next = next;
				}
				if (!using_early_boot) {
					xfree(owner);
				}
			} else {
				prev = owner;
			}

			owner = next;
		}
	}

	iunlock(&borrowpool.lock);

	if (cleaned > 0) {
		print("borrow: cleaned %d resources for pid %d\n", cleaned, p->pid);
	}
}

/* Statistics */
void
borrow_stats(void)
{
	ilock(&borrowpool.lock);
	print("Borrow Checker Statistics:\n");
	print("  Total owners:  %%lud\n", borrowpool.nowners);
	print("  Shared borrows: %%lud\n", borrowpool.nshared);
	print("  Mut borrows:   %%lud\n", borrowpool.nmut);
	iunlock(&borrowpool.lock);
}

/* Dump resource info */
void
borrow_dump_resource(uintptr key)
{
	struct BorrowOwner *owner;
	char *statestr[] = {
		"FREE",
		"EXCLUSIVE",
		"SHARED_OWNED",
		"MUT_LENT",
	};

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil) {
		print("Resource %%#p not found\n", key);
		iunlock(&borrowpool.lock);
		return;
	}

	print("Resource %%#p:\n", key);
	print("  State:          %s\n", statestr[owner->state]);
	print("  Owner:          %s (pid %d)\n",
		owner->owner ? owner->owner->text : "none",
		owner->owner ? owner->owner->pid : -1);
	print("  Shared borrows: %d\n", owner->shared_count);
	print("  Mut borrower:   %s (pid %d)\n",
		owner->mut_borrower ? owner->mut_borrower->text : "none",
		owner->mut_borrower ? owner->mut_borrower->pid : -1);
	print("  Total borrows:  %%lud\n", owner->borrow_count);

	iunlock(&borrowpool.lock);
}

/* ========== System-Level Ownership Functions ========== */

/* Acquire system-level ownership of a resource */
enum BorrowError
borrow_acquire_system(uintptr key, enum BorrowSystemOwner owner)
{
	struct BorrowOwner *own;

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		own = create_owner(key);
		if (own == nil) {
			iunlock(&borrowpool.lock);
			return BORROW_ENOMEM;
		}
	}

	if (own->state != BORROW_FREE) {
		iunlock(&borrowpool.lock);
		return BORROW_EALREADY;
	}

	own->system_owner = owner;
	own->is_system_owned = 1;
	own->state = BORROW_EXCLUSIVE;
	/* Skip timestamp during early boot (before xinit) to avoid timer init */
	if (!using_early_boot) {
		own->acquired_ns = todget(nil, nil);
	} else {
		own->acquired_ns = 0;
	}
	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Release system-level ownership of a resource */
enum BorrowError
borrow_release_system(uintptr key, enum BorrowSystemOwner owner)
{
	struct BorrowOwner *own, *prev;
	ulong hash;

	ilock(&borrowpool.lock);
	own = find_owner(key);
	if (own == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (!own->is_system_owned || own->system_owner != owner) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (own->shared_count > 0 || own->shared_list != nil || own->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EBORROWED;
	}

	own->is_system_owned = 0;
	own->state = BORROW_FREE;
	borrowpool.nowners--;

	/* Remove and free the owner entry from hash table */
	hash = borrow_hash(key);
	prev = nil;
	for (own = borrowpool.owners[hash].head; own != nil; own = own->next) {
		if (own->key == key) {
			if (prev == nil) {
				borrowpool.owners[hash].head = own->next;
			} else {
				prev->next = own->next;
			}
			if (!using_early_boot) {
				xfree(own);
			}
			break;
		}
		prev = own;
	}

	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Transfer system-level ownership between systems */
enum BorrowError
borrow_transfer_system(enum BorrowSystemOwner from, enum BorrowSystemOwner to, uintptr key)
{
	struct BorrowOwner *owner;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTFOUND;
	}

	if (!owner->is_system_owned || owner->system_owner != from) {
		iunlock(&borrowpool.lock);
		return BORROW_ENOTOWNER;
	}

	if (owner->shared_count > 0 || owner->mut_borrower != nil) {
		iunlock(&borrowpool.lock);
		return BORROW_EBORROWED;
	}

	owner->system_owner = to;
	/* Skip timestamp during early boot (before xinit) to avoid timer init */
	if (!using_early_boot) {
		owner->acquired_ns = todget(nil, nil);
	} else {
		owner->acquired_ns = 0;
	}
	iunlock(&borrowpool.lock);
	return BORROW_OK;
}

/* Get system owner of a resource */
enum BorrowSystemOwner
borrow_get_system_owner(uintptr key)
{
	struct BorrowOwner *owner;
	enum BorrowSystemOwner sys_owner;

	ilock(&borrowpool.lock);
	owner = find_owner(key);
	if (owner == nil || !owner->is_system_owned) {
		sys_owner = OWNER_BOOTLOADER;  /* Default */
	} else {
		sys_owner = owner->system_owner;
	}
	iunlock(&borrowpool.lock);

	return sys_owner;
}

/* Check if resource is owned by a specific system */
int
borrow_is_owned_by_system(uintptr key, enum BorrowSystemOwner owner)
{
	struct BorrowOwner *own;
	int owned;

	ilock(&borrowpool.lock);
	own = find_owner(key);
	owned = (own != nil && own->is_system_owned && own->system_owner == owner);
	iunlock(&borrowpool.lock);

	return owned;
}

/* ========== Range-Based Memory Tracking ========== */

/* Static range pool for early boot */
#define MAX_MEMORY_RANGES 32
static struct MemoryRange range_pool[MAX_MEMORY_RANGES];
static int range_count = 0;
static struct MemoryRange *range_list = nil;
static Lock range_lock;

/* Initialize range tracking */
void
memory_range_init(void)
{
	int i;

	range_count = 0;
	range_list = nil;

	/* Clear the pool */
	for (i = 0; i < MAX_MEMORY_RANGES; i++) {
		range_pool[i].start = 0;
		range_pool[i].end = 0;
		range_pool[i].owner = OWNER_BOOTLOADER;
		range_pool[i].next = nil;
	}

	print("memory_range_init: initialized (max %d ranges)\n", MAX_MEMORY_RANGES);
}

/* Add a memory range with ownership (early boot - static pool) */
void
memory_range_add(uintptr start, uintptr end, enum BorrowSystemOwner owner)
{
	struct MemoryRange *range;

	/* During early boot, use static pool */
	if (using_early_boot) {
		if (range_count >= MAX_MEMORY_RANGES) {
			print("memory_range_add: EARLY BOOT pool exhausted (%d/%d)\n",
			      range_count, MAX_MEMORY_RANGES);
			return;
		}

		ilock(&range_lock);

		/* Allocate from static pool */
		range = &range_pool[range_count++];
		range->start = start;
		range->end = end;
		range->owner = owner;

		/* Add to front of list */
		range->next = range_list;
		range_list = range;

		iunlock(&range_lock);

		print("memory_range_add: [%#p-%#p] owner=%d (static)\n", start, end, owner);
	} else {
		/* After xinit(), use dynamic allocation */
		memory_range_add_discovered(start, end, owner);
	}
}

/* Add range with dynamic allocation (after xinit) */
void
memory_range_add_discovered(uintptr start, uintptr end, enum BorrowSystemOwner owner)
{
	struct MemoryRange *range;

	/* Dynamically allocate range entry */
	range = xalloc(sizeof(struct MemoryRange));
	if (range == nil) {
		print("memory_range_add_discovered: xalloc failed for range [%#p-%#p]\n",
		      start, end);
		return;
	}

	ilock(&range_lock);

	range->start = start;
	range->end = end;
	range->owner = owner;

	/* Add to front of list */
	range->next = range_list;
	range_list = range;

	iunlock(&range_lock);

	print("memory_range_add_discovered: [%#p-%#p] owner=%d (dynamic)\n", start, end, owner);
}

/* Remove a memory range */
void
memory_range_remove(uintptr start, uintptr end)
{
	struct MemoryRange *range, *prev;

	ilock(&range_lock);

	prev = nil;
	for (range = range_list; range != nil; range = range->next) {
		if (range->start == start && range->end == end) {
			/* Found it - remove from list */
			if (prev == nil) {
				range_list = range->next;
			} else {
				prev->next = range->next;
			}

			/* Free if dynamically allocated (not from static pool) */
			if (!using_early_boot &&
			    (range < &range_pool[0] || range >= &range_pool[MAX_MEMORY_RANGES])) {
				xfree(range);
			}

			iunlock(&range_lock);
			print("memory_range_remove: [%#p-%#p] removed\n", start, end);
			return;
		}
		prev = range;
	}

	iunlock(&range_lock);
	print("memory_range_remove: [%#p-%#p] not found\n", start, end);
}

/* Dump all memory ranges (debug) */
void
memory_range_dump(void)
{
	struct MemoryRange *range;
	int count = 0;

	ilock(&range_lock);

	print("=== Memory Range Tracking ===\n");
	for (range = range_list; range != nil; range = range->next) {
		print("  [%#p-%#p] owner=%s size=%#p\n",
		      range->start, range->end,
		      range->owner == OWNER_BOOTLOADER ? "BOOTLOADER" : "KERNEL",
		      range->end - range->start);
		count++;
	}
	print("Total: %d ranges\n", count);
	if (using_early_boot) {
		print("Mode: EARLY BOOT (static pool %d/%d used)\n",
		      range_count, MAX_MEMORY_RANGES);
	} else {
		print("Mode: RUNTIME (dynamic allocation)\n");
	}

	iunlock(&range_lock);
}

/* Check capacity - how many more ranges can we add? */
int
memory_range_capacity(void)
{
	if (using_early_boot) {
		return MAX_MEMORY_RANGES - range_count;
	} else {
		/* After xinit, limited only by available memory */
		return 999999;  /* Effectively unlimited */
	}
}

/* Get owner of an address */
enum BorrowSystemOwner
memory_range_get_owner(uintptr addr)
{
	struct MemoryRange *range;
	enum BorrowSystemOwner owner;

	ilock(&range_lock);

	/* Search for containing range */
	for (range = range_list; range != nil; range = range->next) {
		if (addr >= range->start && addr < range->end) {
			owner = range->owner;
			iunlock(&range_lock);
			return owner;
		}
	}

	iunlock(&range_lock);

	/* Not in any tracked range - assume bootloader for now */
	return OWNER_BOOTLOADER;
}

/* Check if requester can access an address */
int
memory_range_check_access(uintptr addr, enum BorrowSystemOwner requester)
{
	enum BorrowSystemOwner owner = memory_range_get_owner(addr);

	/* Owner can always access */
	if (owner == requester)
		return 1;

	/* For now, deny cross-owner access */
	return 0;
}

/* ========== Per-Page Tracking (Runtime) ========== */

/* Acquire ownership of a physical address range - PAGE BY PAGE */
enum BorrowError
borrow_acquire_range_phys(uintptr start_pa, usize size, enum BorrowSystemOwner owner)
{
	uintptr pa;
	enum BorrowError err;

	/* IMPORTANT: Only use this after xinit() for runtime tracking!
	 * For boot coordination, use memory_range_add() instead */
	if (using_early_boot) {
		print("borrow_acquire_range_phys: ERROR - called during early boot\n");
		print("  Use memory_range_add() for boot coordination instead\n");
		return BORROW_EINVAL;
	}

	/* Acquire ownership for each 4KB page in the range */
	for (pa = start_pa; pa < start_pa + size; pa += 0x1000) {
		err = borrow_acquire_system(pa, owner);
		if (err != BORROW_OK && err != BORROW_EALREADY) {
			/* Rollback on error */
			while (pa > start_pa) {
				pa -= 0x1000;
				borrow_release_system(pa, owner);
			}
			return err;
		}
	}

	return BORROW_OK;
}

/* Check if entire range is owned by a specific system */
int
borrow_range_owned_by_system(uintptr start_pa, usize size, enum BorrowSystemOwner owner)
{
	uintptr pa;

	/* During early boot, check range tracking instead */
	if (using_early_boot) {
		/* Check if entire range has same owner */
		for (pa = start_pa; pa < start_pa + size; pa += 0x1000) {
			if (memory_range_get_owner(pa) != owner)
				return 0;
		}
		return 1;
	}

	/* Runtime: check page-by-page */
	for (pa = start_pa; pa < start_pa + size; pa += 0x1000) {
		if (!borrow_is_owned_by_system(pa, owner))
			return 0;
	}

	return 1;
}

/* Check if a system can access a physical address range */
int
borrow_can_access_range_phys(uintptr start_pa, usize size, enum BorrowSystemOwner requester)
{
	uintptr pa;

	/* During early boot, check range tracking */
	if (using_early_boot) {
		for (pa = start_pa; pa < start_pa + size; pa += 0x1000) {
			if (!memory_range_check_access(pa, requester))
				return 0;
		}
		return 1;
	}

	/* Runtime: check page-by-page ownership */
	for (pa = start_pa; pa < start_pa + size; pa += 0x1000) {
		enum BorrowSystemOwner owner = borrow_get_system_owner(pa);
		if (owner != requester)
			return 0;
	}

	return 1;
}

/* ========== Memory Coordination Functions ========== */

/* Global memory coordination state */
static struct MemoryCoordination mem_coord;

/* Initialize memory coordination system */
void
boot_memory_coordination_init(void)
{
	mem_coord.state = MEMORY_BOOTLOADER;
	mem_coord.current_owner = OWNER_BOOTLOADER;
	mem_coord.coordination_enabled = 1;

	/* Initialize range-based tracking */
	memory_range_init();

	print("boot_memory_coordination_init: initialized (state=BOOTLOADER)\n");
}

/* Transfer bootloader memory to kernel - simple state transition */
void
transfer_bootloader_to_kernel(void)
{
	/* Simple state transition - no per-page tracking needed */
	mem_coord.state = MEMORY_KERNEL_ACTIVE;
	mem_coord.current_owner = OWNER_KERNEL;

	print("transfer_bootloader_to_kernel: ownership transferred (BOOTLOADER â†’ KERNEL)\n");
}

/* Establish memory ownership zones using range-based tracking (STATIC) */
void
establish_memory_ownership_zones(void)
{
	/* Define memory regions using efficient range tracking
	 * Each range covers potentially many pages with single entry
	 *
	 * NOTE: These are HARDCODED for early boot. Use
	 * establish_memory_ownership_zones_dynamic() after xinit()
	 * to discover actual kernel layout dynamically.
	 */

	/* Kernel code region: 0x200000 - 0x400000 (2MB) */
	memory_range_add(0x200000, 0x400000, OWNER_KERNEL);

	/* Kernel data region: 0x400000 - 0x600000 (2MB) */
	memory_range_add(0x400000, 0x600000, OWNER_KERNEL);

	/* CR3 continuation region: 0x600000 - 0x700000 (1MB) */
	memory_range_add(0x600000, 0x700000, OWNER_KERNEL);

	/* Page tables region: 0x210000 - 0x220000 (64KB) */
	memory_range_add(0x210000, 0x220000, OWNER_KERNEL);

	mem_coord.state = MEMORY_COORDINATED;

	print("establish_memory_ownership_zones: zones established (static, %d ranges)\n",
	      4);
}

/* Establish memory ownership zones DYNAMICALLY (after xinit) */
void
establish_memory_ownership_zones_dynamic(void)
{
	extern Conf conf;
	int i;
	uintptr start, region_end;

	if (using_early_boot) {
		print("establish_memory_ownership_zones_dynamic: ERROR - call after xinit()\n");
		return;
	}

	print("establish_memory_ownership_zones_dynamic: discovering memory from conf.mem[]\n");

	/* Discover kernel memory regions from conf.mem[] */
	for (i = 0; i < nelem(conf.mem); i++) {
		if (conf.mem[i].npage == 0)
			continue;

		start = conf.mem[i].base;
		region_end = start + (conf.mem[i].npage * BY2PG);

		/* Determine ownership based on region type */
		if (start >= conf.mem[i].kbase && start < conf.mem[i].klimit) {
			/* Kernel memory */
			memory_range_add_discovered(start, region_end, OWNER_KERNEL);
			print("  Kernel region [%#p-%#p] size=%#p\n",
			      start, region_end, region_end - start);
		} else {
			/* User/free memory - not tracked initially */
			print("  User/free region [%#p-%#p] size=%#p (not tracked)\n",
			      start, region_end, region_end - start);
		}
	}

	print("establish_memory_ownership_zones_dynamic: discovery complete\n");
	memory_range_dump();
}

/* Validate memory coordination ready - check zones are established */
int
validate_memory_coordination_ready(void)
{
	/* Check coordination enabled */
	if (!mem_coord.coordination_enabled) {
		print("validate_memory_coordination_ready: coordination disabled\n");
		return 0;
	}

	/* Check we're in coordinated state */
	if (mem_coord.state != MEMORY_COORDINATED && mem_coord.state != MEMORY_KERNEL_ACTIVE) {
		print("validate_memory_coordination_ready: wrong state %d\n", mem_coord.state);
		return 0;
	}

	/* Check kernel owns critical region (sample check) */
	if (memory_range_get_owner(0x200000) != OWNER_KERNEL) {
		print("validate_memory_coordination_ready: kernel doesn't own 0x200000\n");
		return 0;
	}

	print("validate_memory_coordination_ready: ready for CR3 switch\n");
	return 1;
}

/* Check if memory system is ready before CR3 switch */
int
memory_system_ready_before_cr3(void)
{
	/* Check if HHDM offset is known */
	if(saved_limine_hhdm_offset == 0)
		return 0;

	/* Check if memory coordination is initialized */
	if(mem_coord.state != MEMORY_KERNEL_ACTIVE)
		return 0;

	/* Check borrow pool accessibility */
	if(borrowpool.owners == nil || borrowpool.nbuckets == 0)
		return 0;

	return 1;
}

/* Validate that memory system is operational after CR3 switch */
int
post_cr3_memory_system_operational(void)
{
	/* After CR3 switch, verify we can still access our data structures */
	if (borrowpool.owners == nil || borrowpool.nbuckets == 0) {
		print("post_cr3_memory_system_operational: borrow pool inaccessible\n");
		return 0;
	}

	/* Verify coordination state is accessible */
	if (mem_coord.state != MEMORY_KERNEL_ACTIVE) {
		print("post_cr3_memory_system_operational: unexpected state %d\n", mem_coord.state);
		return 0;
	}

	print("post_cr3_memory_system_operational: memory system operational\n");
	return 1;
}
